{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLHeU7j17G9A"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goMUTPqe4QWS"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jckrP1e24KhJ",
        "outputId": "68695a26-ff47-4756-b2a4-85fe5114e673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of lines in train dot file 10780437\n",
            "# of lines in valid dot file 1120192\n",
            "# of lines in valid txt file 1120192\n",
            "# of lines in test dot file 1255018\n",
            "# of lines in test txt file 1255018\n"
          ]
        }
      ],
      "source": [
        "#Temp cell to get no. of lines of each dataset for preliminary analysis\n",
        "\n",
        "with open('wiki.train.dot', \"r\") as f:\n",
        "  texts_train = f.read()\n",
        "with open('wiki.valid.dot', \"r\") as f:\n",
        "  texts_valid_dot = f.read()\n",
        "with open('wiki.valid.txt', \"r\") as f:\n",
        "  texts_valid_txt = f.read() \n",
        "with open('wiki.test.dot', \"r\") as f:\n",
        "  texts_test_dot = f.read()\n",
        "with open('wiki.test.txt', \"r\") as f:\n",
        "  texts_test_txt = f.read()\n",
        "\n",
        "print('# of lines in train dot file', len(texts_train))\n",
        "print('# of lines in valid dot file', len(texts_valid_dot))\n",
        "print('# of lines in valid txt file', len(texts_valid_txt))\n",
        "print('# of lines in test dot file', len(texts_test_dot))\n",
        "print('# of lines in test txt file', len(texts_test_txt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8KCKYSGyiAN",
        "outputId": "47ad7dbb-f3b5-429f-944e-88eb9bcde170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of lines in dot file 1255018\n",
            "# of lines in txt file 1255018\n",
            "examples of corrupted words: ['·inal', 'be·ng', '<unk·', 'he·o', 'becaus·', '·unk>', 'direc·ion', 'relea·e', 'furth·r', 'r·al']\n",
            "examples of their labels: ['final', 'being', '<unk>', 'hero', 'because', '<unk>', 'direction', 'release', 'further', 'real']\n"
          ]
        }
      ],
      "source": [
        "lines_dot = []\n",
        "lines_txt = []\n",
        "corrupted_words = []\n",
        "corrupted_labels = []    # the true label of the corrupted words\n",
        "\n",
        "with open('wiki.train.dot', \"r\") as f:\n",
        "  texts_train = f.read()\n",
        "with open('wiki.test.dot', \"r\") as f:\n",
        "  texts_dot = f.read()\n",
        "with open('wiki.test.txt', \"r\") as f:\n",
        "  texts_txt = f.read()\n",
        "\n",
        "print('# of lines in dot file', len(texts_dot))\n",
        "print('# of lines in txt file', len(texts_txt))\n",
        "\n",
        "\n",
        "# print('# of words in dot:', len(texts_dot.split(' ')))\n",
        "# print('# of words in txt:', len(texts_txt.split(' ')))\n",
        "\n",
        "raw_words_dot= texts_dot.split(' ')\n",
        "raw_words_txt= texts_txt.split(' ')\n",
        "\n",
        "for i, word in enumerate(raw_words_dot):\n",
        "    if chr(183) in word:\n",
        "        corrupted_words.append(word)\n",
        "        corrupted_labels.append(raw_words_txt[i])\n",
        "\n",
        "print('examples of corrupted words:', corrupted_words[-10:])\n",
        "print('examples of their labels:', corrupted_labels[-10:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_MgOzm84W4-"
      },
      "source": [
        "# **Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prmop9e935xb"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def extractTokens(texts):\n",
        "    tokens = []\n",
        "    # -- Remove punctuation and new lines\n",
        "    texts = re.sub(r'[^\\w\\s\\·]', '', texts)\n",
        "    texts = re.sub(r'[\\n]', ' ', texts)\n",
        "    # -- Split into words by space\n",
        "    words = texts.split(' ')\n",
        "    # -- Remove words shorter than 2 charaters\n",
        "    # for word in words:\n",
        "    #     if len(word) < 2 :\n",
        "    #         words.remove(word)\n",
        "    # print('# of words after remove:', len(words))\n",
        "\n",
        "    # -- Remove stop words ('unk' and 'usp')\n",
        "    # -- Remove capitalization\n",
        "    stop_words = ['unk', '·nk', 'u·k', 'un·', '·unk', 'unk·', '']\n",
        "    tokens += [x.lower() for x in words if x not in stop_words]\n",
        "    # if i == 3300: print('len of words at line', i, ':', len(words))\n",
        "    # for word in words:\n",
        "    #     if chr(183) in word:\n",
        "    #         print(word)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrGl4SUl1jN-",
        "outputId": "7dff5351-180b-4d49-feb1-26d62162ab18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of words in dot file: 191126\n",
            "# of words in dot file: 191126\n",
            "examples of processed words in dot file: ['actor', 'he', 'had', 'a', 'guest', 'starring', 'role', 'on', 'the', 'television', 'series']\n"
          ]
        }
      ],
      "source": [
        "tokens_dot = extractTokens(texts_dot)\n",
        "tokens_txt = extractTokens(texts_txt)\n",
        "print('# of words in dot file:', len(tokens_dot))\n",
        "print('# of words in dot file:', len(tokens_txt))\n",
        "print('examples of processed words in dot file:', tokens_dot[9:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WhzYuFUPklR"
      },
      "source": [
        "## Extract corrupted words and their uncorrupted version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08mt77kS_hr0",
        "outputId": "55f70b75-c489-498a-ab02-d91534198bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len of corrupted: 1154\n",
            "len of uncorrupted: 189972\n",
            "['som·thing', 'sar·h', '·inal', 'be·ng', 'he·o', 'becaus·', 'direc·ion', 'relea·e', 'furth·r', 'r·al']\n",
            "['something', 'sarah', 'final', 'being', 'hero', 'because', 'direction', 'release', 'further', 'real']\n"
          ]
        }
      ],
      "source": [
        "corrupted_tokens_dot = []\n",
        "uncorrupted_tokens_dot = []\n",
        "label_tokens_txt = []\n",
        "\n",
        "for i, token in enumerate(tokens_dot):\n",
        "    if chr(183) in token:\n",
        "        corrupted_tokens_dot.append(token)\n",
        "        label_tokens_txt.append(tokens_txt[i])\n",
        "    else:\n",
        "        uncorrupted_tokens_dot.append(token)\n",
        "print('len of corrupted:', len(corrupted_tokens_dot))\n",
        "print('len of uncorrupted:', len(uncorrupted_tokens_dot))\n",
        "print(corrupted_tokens_dot[-10:])\n",
        "print(label_tokens_txt[-10:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "oNpzCHdvQvuR",
        "outputId": "27713e15-f276-4310-9124-032084b3b2de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'·'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chr(183)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUJSpYZSYNVI"
      },
      "source": [
        "## **BASIC NAIVE BAYES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH6eDP83YZCh"
      },
      "outputs": [],
      "source": [
        "def basic_nb (curr, train_data):\n",
        "    # curr = corrupted_tokens_dot[0]\n",
        "    split = curr.split('·')\n",
        "    # -- If the black dot is at front or end\n",
        "    if len(split) == 1:\n",
        "        if curr[0] == '·':\n",
        "            pattern = '[^\\w][\\w]{}[^\\w]'.format(split)\n",
        "        elif curr[-1] == '·':\n",
        "            pattern = '[^\\w]{}[\\w][^\\w]'.format(split)\n",
        "    # -- If the black dot is in the middle\n",
        "    elif len(split) == 2:\n",
        "        pattern = '[^\\w]{0}[\\w]{1}[^\\w]'.format(split[0], split[1])\n",
        "\n",
        "    matches = re.findall(pattern, train_data)\n",
        "    trims = []\n",
        "    for match in matches:\n",
        "        trims.append(re.sub(r'[^\\w]', '', match))\n",
        "    # print('corrupted word:', curr)\n",
        "    # print('found matches:', trims)\n",
        "    uniques = list(set(trims))\n",
        "    pred = ''\n",
        "    max_count = float('-inf')\n",
        "    for unique in uniques:\n",
        "        if trims.count(unique) > max_count:\n",
        "            pred = unique\n",
        "            max_count = trims.count(unique)\n",
        "    \n",
        "    return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd1lXEMeUt6L"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxXjhEpoUl5X",
        "outputId": "e0a6a1c8-f0d0-423d-a25f-7cafdf85fc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 84.32%\n",
            "time elapsed: 338.3108642101288s\n",
            "ratio of no match: 0.07712305025996534\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "correct_pred = 0.0\n",
        "no_match = 0.0\n",
        "for i, token in enumerate(corrupted_tokens_dot):\n",
        "    pred = basic_nb(token, texts_train)\n",
        "    if pred == label_tokens_txt[i]:\n",
        "        correct_pred += 1\n",
        "    if pred == '':\n",
        "        no_match += 1\n",
        "acc = correct_pred/len(corrupted_tokens_dot)\n",
        "end = time.time()\n",
        "print('accuracy: {:.2f}%'.format(acc*100))\n",
        "print('time elapsed: {}s'.format(end - start))\n",
        "print('ratio of no match:', no_match/len(corrupted_tokens_dot))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwGp7Q7Ii6pj",
        "outputId": "7533ba35-451a-47d1-90df-cf5601b7b9f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['usa', 'asa', 'bsa']\n",
            "[^\\w][\\w]ab[^\\w]\n"
          ]
        }
      ],
      "source": [
        "# -- Just try random stuff\n",
        "match = re.findall('[a-z]?sa', 'usa asa bsa')\n",
        "if match:\n",
        "    print(match)\n",
        "\n",
        "split = ' abc'.split()\n",
        "print('[^\\w][\\w]{0}{1}[^\\w]'.format('a', 'b'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDqTa_oVo7qR"
      },
      "source": [
        "## **JAMPSELL (improved Norvig)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHrWXMMQPaE3"
      },
      "source": [
        "Package: https://github.com/bakwc/JamSpell#python\n",
        "\n",
        "Install in CoLab: https://colab.research.google.com/drive/1aFk8-7nq3oAp402jjLGLpEb2Nzq210Eo#scrollTo=WQpKf25MYFtA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfiTxg6Ip2ft"
      },
      "outputs": [],
      "source": [
        "# !ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIRdRdb7pDRg"
      },
      "outputs": [],
      "source": [
        "# !brew install swig3\n",
        "# !pip install jamspell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rr26nBT5IL9",
        "outputId": "e023a435-fb3d-4d39-f4d9-ddafbc30cdc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (768 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install swig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3-3v_105SlC",
        "outputId": "53f4bef0-1186-41c8-d161-221df403885b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jamspell\n",
            "  Downloading jamspell-0.0.12.tar.gz (174 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 8.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: jamspell\n",
            "  Building wheel for jamspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jamspell: filename=jamspell-0.0.12-cp37-cp37m-linux_x86_64.whl size=1347634 sha256=fadc396d0d00ed8b3574302c28265edbe92037bfe9648b32fe85c12025d1e510\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/df/9c/9b335e69aa0f28e7f508ec0ebefadcc703f168beb52ae7ebe7\n",
            "Successfully built jamspell\n",
            "Installing collected packages: jamspell\n",
            "Successfully installed jamspell-0.0.12\n"
          ]
        }
      ],
      "source": [
        "!sudo pip install jamspell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_MhTuxQIKbf"
      },
      "source": [
        "## Train language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDWAQORMIMiY",
        "outputId": "fb65cb67-2c2e-487a-afd0-7e1ffd523b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "502NurQ9Ka0W"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bakwc/JamSpell.git\n",
        "!mkdir /content/JamSpell/build\n",
        "!cmake /content/JamSpell\n",
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-lFxFaKNOHt"
      },
      "outputs": [],
      "source": [
        "# !./main/jamspell train alphabet_en.txt wiki.valid.txt model_validset.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-27mX4IQ0uc"
      },
      "source": [
        "## Use pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs15C1MY5TwJ",
        "outputId": "efdfc525-76ad-4990-df5e-c415cad840b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-30 23:27:32--  https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bakwc/JamSpell-models/master/en.tar.gz [following]\n",
            "--2021-11-30 23:27:33--  https://raw.githubusercontent.com/bakwc/JamSpell-models/master/en.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36611828 (35M) [application/octet-stream]\n",
            "Saving to: ‘en.tar.gz’\n",
            "\n",
            "en.tar.gz           100%[===================>]  34.92M   182MB/s    in 0.2s    \n",
            "\n",
            "2021-11-30 23:27:34 (182 MB/s) - ‘en.tar.gz’ saved [36611828/36611828]\n",
            "\n",
            "en.bin\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz\n",
        "!tar -xvf en.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUdoXRyWM50W"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3KL-XTmM5US"
      },
      "outputs": [],
      "source": [
        "# !python ./JamSpell/evaluate/evaluate.py -a alphabet_en.txt -jsp model_validset.bin -mx 50000 wiki.test.dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrhCKCEy5Zai"
      },
      "source": [
        "**Do restart Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piMtnPq_Ok_i"
      },
      "outputs": [],
      "source": [
        "import jamspell\n",
        "from importlib import reload\n",
        "reload(jamspell)\n",
        "corrector = jamspell.TSpellCorrector()\n",
        "# corrector.LoadLangModel('model_validset.bin')\n",
        "corrector.LoadLangModel('en.bin')\n",
        "assert corrector.LoadLangModel('en.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9tHepf15h8q"
      },
      "outputs": [],
      "source": [
        "# corrector.FixFragment('I am the begt spell cherken!')\n",
        "# u'I am the best spell checker!'\n",
        "\n",
        "# corrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 3)\n",
        "# # (u'best', u'beat', u'belt', u'bet', u'bent', ... )\n",
        "\n",
        "# corrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 5)\n",
        "# # (u'checker', u'chicken', u'checked', u'wherein', u'coherent', ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcM5T9hfehCA",
        "outputId": "31ed7af5-8409-47b8-8fa7-02b2db1bb247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "robert robert is an english film television and theatre actor he had a guest starring role on the television series the bill in 2000 this was followed by a starring role in the play herons written by \n"
          ]
        }
      ],
      "source": [
        "# -- Replace black dot with letter 'q' to adjust for model\n",
        "tokens_dot_adj = []\n",
        "for token in tokens_dot:\n",
        "    if re.search('·', token):\n",
        "        tokens_dot_adj.append(re.sub(r'·', 'q', token))\n",
        "    else:\n",
        "        tokens_dot_adj.append(token)\n",
        "# -- Join the processed list of words back into a doc without punctuations\n",
        "text_dot_processed = ' '.join(tokens_dot_adj)\n",
        "# text_txt_processed = ' '.join(tokens_txt)\n",
        "\n",
        "print(text_dot_processed[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7F4GcczqT6B"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "pred2 = corrector.FixFragment(text_dot_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWwN5_Hx3DJw",
        "outputId": "76c743d3-5026-4f3b-f920-5488013e9e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 91.33%\n",
            "time elapsed: 764.6844639778137s\n"
          ]
        }
      ],
      "source": [
        "mis_pred2 = 0.0\n",
        "remain_mis = []\n",
        "remain_mis_ori = []\n",
        "remain_mis_label = []\n",
        "# -- See how many dots left\n",
        "remain_dot = []\n",
        "pred2_token = pred2.split(' ')\n",
        "for i, token in enumerate(pred2_token):\n",
        "    if re.search('·', tokens_dot[i]):\n",
        "        # remain_dot.append(token)\n",
        "        # token = re.sub(r'·','', token)\n",
        "        if not token == tokens_txt[i]:\n",
        "            mis_pred2 += 1\n",
        "            remain_mis.append(token)\n",
        "            remain_mis_ori.append(tokens_dot[i])\n",
        "            remain_mis_label.append(tokens_txt[i])\n",
        "acc2 = 1-(mis_pred2/len(corrupted_tokens_dot))\n",
        "end = time.time()\n",
        "print('accuracy: {:.2f}%'.format(acc2*100))\n",
        "print('time elapsed: {}s'.format(end - start))\n",
        "# print('remaining words with dot:', remain_dot)\n",
        "# print('# of dot remaining:', len(remain_dot))\n",
        "# print('ratio of no match:', no_match/len(corrupted_tokens_dot))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrymyZVPUrS2",
        "outputId": "af86ac52-e97a-42e5-fee9-826ad71975bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['wallqnia', 'slip', 'fact', 'ship', '194a', '19s4', 'slowing', 'assault', 'year', 'the', 'help', 'line', 'will', 'qalestro', 'pounded', 'q876', '1a64', 'played', 'arab']\n",
            "['wall·nia', '·lip', 'fa·t', 'ship·', '194·', '19·4', '·lowing', 'assault·', '·ear', 'the·', 'hel·', 'line·', '·ill', '·alestro', 'pounde·', '·876', '1·64', 'pla·ed', '·rab']\n",
            "['wallonia', 'clip', 'fast', 'ships', '1943', '1944', 'blowing', 'assaults', 'near', 'them', 'held', 'lines', 'hill', 'palestro', 'pounder', '1876', '1964', 'placed', 'crab']\n",
            "# of mis predictions: 100\n"
          ]
        }
      ],
      "source": [
        "print(remain_mis[1:20])\n",
        "print(remain_mis_ori[1:20])\n",
        "print(remain_mis_label[1:20])\n",
        "print('# of mis predictions:', int(mis_pred2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzWDpxI726w5"
      },
      "source": [
        "## **FFNN** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzXq-3wVtNY2",
        "outputId": "59d57bf4-3486-443b-f337-560acb73ea27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VddRFDqM3GzE"
      },
      "outputs": [],
      "source": [
        "with open('wiki.valid.txt', \"r\") as f:\n",
        "  texts_valid_txt = f.read() \n",
        "with open('wiki.test.dot', \"r\") as f:\n",
        "  texts_test_dot = f.read()\n",
        "with open('wiki.test.txt', \"r\") as f:\n",
        "  texts_test_txt = f.read()\n",
        "\n",
        "texts_valid_txt = re.sub(r'<unk>', '', texts_valid_txt)\n",
        "texts_valid_txt = re.sub(r'[\\n]', ' ', texts_valid_txt).upper()\n",
        "# Remove <unk> in the test.txt along with its correspondence in text.dot\n",
        "idx_unk = [(m.start(0), m.end(0)) for m in re.finditer('<unk>', texts_test_txt)]\n",
        "l = list(texts_test_txt)\n",
        "for idx in idx_unk[::-1]:\n",
        "    del(l[idx[0]:idx[1]])\n",
        "texts_test_txt = \"\".join(l)\n",
        "l = list(texts_test_dot)\n",
        "for idx in idx_unk[::-1]:\n",
        "    del(l[idx[0]:idx[1]])\n",
        "texts_test_dot = \"\".join(l)\n",
        "texts_test_dot = re.sub(r'[\\n]', ' ', texts_test_dot).upper()\n",
        "texts_test_txt = re.sub(r'[\\n]', ' ', texts_test_txt).upper()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHeEM2xmzpY6",
        "outputId": "a2a512c5-fcba-492f-8ff0-1dd4aa3258d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' SOM', ' SAR', 'THE ', 'N BE', 'E HE', 'CAUS', 'IREC', 'ELEA', 'URTH', 'SO R']\n",
            "['E', 'A', 'F', 'I', 'R', 'E', 'T', 'S', 'E', 'E']\n"
          ]
        }
      ],
      "source": [
        "# -- Extract windows for black dots from test set and their labels\n",
        "WINDOW = 4\n",
        "idx_dot = [m.start(0) for m in re.finditer(chr(183), texts_test_dot)]\n",
        "window_test = []\n",
        "label_test = []\n",
        "for idx in idx_dot:\n",
        "    window_test.append(texts_test_dot[(idx-WINDOW):idx])\n",
        "    label_test.append(texts_test_txt[idx])\n",
        "print(window_test[-10:])\n",
        "print(label_test[-10:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create lookup tables"
      ],
      "metadata": {
        "id": "t8PgyjbJbgin"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx_gUuv0t55r"
      },
      "source": [
        "Reference: https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u1-OxY2_7jM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9ec4d6-0183-40f3-c897-d24aff834506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of ascii list: 36\n"
          ]
        }
      ],
      "source": [
        "asciis = [range(32,35), 39, range(44,47), range(58,60), 63, range(65,91)]\n",
        "ascii_ls = np.array([], dtype=int)\n",
        "for x in asciis:\n",
        "    ascii_ls = np.append(ascii_ls, x)\n",
        "print('len of ascii list:', len(ascii_ls))\n",
        "# for ascii in ascii_ls:\n",
        "#     if ascii != 40 and ascii != 41:\n",
        "#         print(ascii, ':', len(re.findall('\\\\'+chr(ascii), texts_valid_txt)))\n",
        "char_ls = []\n",
        "for x in ascii_ls:\n",
        "    char_ls.append(chr(x))\n",
        "lookup_embed = {k:v for k,v in zip(char_ls, range(len(ascii_ls)))}\n",
        "lookup_char = {k:v for k,v in zip(range(len(ascii_ls)), char_ls)}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "ci5Gq64K7SO9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8tCBArRDmrP"
      },
      "source": [
        "Reference: https://stackoverflow.com/questions/57029817/how-to-concatenate-embedding-layer-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aLrvX2CO4HwX"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, h_sizes, n_features, num_words, embed_dim, out_size, dropout=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = len(h_sizes)  # hidden + input\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(num_words, embed_dim)\n",
        "        self.hidden = torch.nn.ModuleList()\n",
        "        self.bnorm = torch.nn.ModuleList()\n",
        "        self.ReLU = torch.nn.ReLU()\n",
        "        if dropout is not None:\n",
        "            self.dropout = torch.nn.ModuleList()\n",
        "        else:\n",
        "            self.dropout = None\n",
        "\n",
        "        for k in range(self.num_layers):\n",
        "            if k == 0:\n",
        "                input_dim = n_features*embed_dim\n",
        "            else:\n",
        "                input_dim = h_sizes[k-1]\n",
        "                \n",
        "            self.hidden.append(torch.nn.Linear(input_dim, h_sizes[k]))\n",
        "            self.bnorm.append(torch.nn.BatchNorm1d(h_sizes[k]))\n",
        "            if self.dropout is not None:\n",
        "                self.dropout.append(torch.nn.Dropout(p=dropout))\n",
        "        # Output layer\n",
        "        self.out = torch.nn.Linear(h_sizes[-1], out_size)\n",
        "        # Cosine similarity layer\n",
        "        self.cos = torch.nn.CosineSimilarity()\n",
        "        # Softmax layer\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        # print('# of layers:', self.num_layers)\n",
        "        # print('len of modulelist:', len(self.bnorm))\n",
        "\n",
        "    def forward(self, word_ix):\n",
        "\n",
        "        for l in range(self.num_layers):\n",
        "            if l == 0:\n",
        "                # Prepare input embeddings in batches (batch_size, n_features*embed_dim)\n",
        "                batch_size = word_ix.shape[0]\n",
        "                embeds = 0\n",
        "                for sample in range(batch_size):\n",
        "                    if sample == 0:\n",
        "                        embeds = self.embedding(word_ix[0]).view(1,-1)\n",
        "                    else:\n",
        "                        embeds = torch.vstack((embeds, self.embedding(word_ix[sample]).view(1,-1)))\n",
        "                # NOTE:\n",
        "                # embeds has a shape of (batch_size, 1, embed_dim)\n",
        "                # inorder to merge this change this with x, reshape this to\n",
        "                # (batch_size, embed_dim)\n",
        "                # embeds = embeds.view(embeds.shape[0], embeds.shape[2])\n",
        "\n",
        "                # print('shape of input:', embeds.view(1,-1).shape)\n",
        "                x = self.hidden[l](embeds)\n",
        "                # x = self.ReLU(x)\n",
        "                x = self.bnorm[l](x)\n",
        "                if self.dropout is not None:\n",
        "                    x = self.dropout[l](x)\n",
        "\n",
        "            else:\n",
        "                x = self.hidden[l](x)\n",
        "                # x = self.ReLU(x)\n",
        "                x = self.bnorm[l](x)\n",
        "                if self.dropout is not None:\n",
        "                    x = self.dropout[l](x)\n",
        "            x = self.ReLU(x)\n",
        "\n",
        "        out = self.out(x)\n",
        "\n",
        "        NUM_TARGETS = self.embedding.weight.shape[0]\n",
        "        # Dot product\n",
        "        all_idx = []\n",
        "        all_idx.extend(range(NUM_TARGETS))\n",
        "        all_idx = torch.LongTensor(all_idx).to(device)\n",
        "        cos_sim = torch.mm(out, torch.t(self.embedding(all_idx)))\n",
        "        # print('shape of cos_sim:', cos_sim.shape)\n",
        "        output = self.softmax(cos_sim)\n",
        "        # print('output layer shape:', output.shape)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "g1JyAooWtyxT",
        "outputId": "6219eca2-8500-480b-ef4d-fe5f1a1c3f1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nNUM_TARGETS = len(ascii_ls)\\nEMBED_DIM = 10\\nWINDOW = 4\\nNUM_LAYERS = 4\\n# x = np.random.rand(5, NUM_FEATURES)\\ny = np.random.rand(1, NUM_TARGETS)\\n\\nword_ix = np.arange(WINDOW)\\nprint('word_ix:', word_ix)\\n\\ny_train = torch.from_numpy(y).float().to(device)\\n\\nh_sizes = [10, 5, 15, 10]\\n\\nnet = Net(h_sizes=h_sizes, n_features = WINDOW, num_words=NUM_TARGETS, embed_dim=EMBED_DIM, out_size=EMBED_DIM,dropout=None)     # define the network\\nprint(net)  # net architecture\\nnet = net.float()\\nnet.to(device)\\n\\noptimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=.01)\\nloss_func = torch.nn.CrossEntropyLoss()  # this is for regression mean squared loss\\n\\n# one training loop\\nprediction = net(word_ix)     # input x and predict based on x\\nprint('shape of prediction:', prediction.shape)\\n\\nprint('for loss func, out shape:', prediction.shape, 'y shape:', y_train.shape)\\nloss = loss_func(prediction, y_train)     # must be (1. nn output, 2. target)\\n\\noptimizer.zero_grad()   # clear gradients for next train\\nloss.backward()         # backpropagation, compute gradients\\noptimizer.step()        # apply gradients       \\n\""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"\n",
        "NUM_TARGETS = len(ascii_ls)\n",
        "EMBED_DIM = 10\n",
        "WINDOW = 4\n",
        "NUM_LAYERS = 4\n",
        "# x = np.random.rand(5, NUM_FEATURES)\n",
        "y = np.random.rand(1, NUM_TARGETS)\n",
        "\n",
        "word_ix = np.arange(WINDOW)\n",
        "print('word_ix:', word_ix)\n",
        "\n",
        "y_train = torch.from_numpy(y).float().to(device)\n",
        "\n",
        "h_sizes = [10, 5, 15, 10]\n",
        "\n",
        "net = Net(h_sizes=h_sizes, n_features = WINDOW, num_words=NUM_TARGETS, embed_dim=EMBED_DIM, out_size=EMBED_DIM,dropout=None)     # define the network\n",
        "print(net)  # net architecture\n",
        "net = net.float()\n",
        "net.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=.01)\n",
        "loss_func = torch.nn.CrossEntropyLoss()  # this is for regression mean squared loss\n",
        "\n",
        "# one training loop\n",
        "prediction = net(word_ix)     # input x and predict based on x\n",
        "print('shape of prediction:', prediction.shape)\n",
        "\n",
        "print('for loss func, out shape:', prediction.shape, 'y shape:', y_train.shape)\n",
        "loss = loss_func(prediction, y_train)     # must be (1. nn output, 2. target)\n",
        "\n",
        "optimizer.zero_grad()   # clear gradients for next train\n",
        "loss.backward()         # backpropagation, compute gradients\n",
        "optimizer.step()        # apply gradients       \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n6eCEywz_JSo"
      },
      "outputs": [],
      "source": [
        "def train(train_data, batch_size, window, model, loss_func, optimizer, reg_option=False):\n",
        "    model.train()\n",
        "    n_batches = int((len(train_data)-window) / batch_size)\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    correct = 0\n",
        "    now = datetime.datetime.now()\n",
        "    \n",
        "    for batch in range(n_batches):\n",
        "        # Initialize\n",
        "        word_ix = np.empty([0, window])\n",
        "        y_label = np.array([])\n",
        "        y = torch.zeros([0, len(char_ls)], dtype=torch.float32)\n",
        "        # word_ix includes a n_batches of text window; if not in ascii list, replace with random\n",
        "        for sample in range(batch_size):\n",
        "            word_ix_sample = []\n",
        "            for x in train_data[batch+sample:(batch+sample+window)]:\n",
        "                if x in lookup_embed.keys():\n",
        "                    word_ix_sample.append(lookup_embed[x])\n",
        "                else:\n",
        "                    word_ix_sample.append(np.random.randint(0,len(char_ls)-1))\n",
        "            word_ix = np.vstack((word_ix, word_ix_sample))\n",
        "            y_label = np.append(y_label, train_data[batch+sample+window])\n",
        "            word_iy_sample = lookup_embed[y_label[-1]] if y_label[-1] in lookup_embed.keys() else np.random.randint(0,len(char_ls)-1)\n",
        "            y_sample = torch.zeros([1, len(char_ls)], dtype=torch.float32)\n",
        "            y_sample[0, word_iy_sample] = 1\n",
        "            y = torch.vstack((y, y_sample))\n",
        "        #------ y is an embedding matrix with the label embedding as the only non-zero row\n",
        "        # y = torch.Tensor(len(ascii_ls), model.embedding(torch.LongTensor([0])).shape[1])\n",
        "        # y.zero_()\n",
        "        # y[word_iy] = model.embedding(torch.LongTensor([word_iy]).view(1,-1)).detach()\n",
        "        #------------------------------------------------------------------\n",
        "        # y = torch.zeros([1, len(ascii_ls)], dtype=torch.float32)\n",
        "        # y[0, word_iy] = 1\n",
        "        word_ix, y = torch.LongTensor(word_ix).to(device), y.to(device)\n",
        "        # print('shape of word_ix:', word_ix.shape)\n",
        "        # print('y:', y)\n",
        "        # print('shape of y:', y.shape)\n",
        "\n",
        "        \n",
        "        # make some predictions and get the error\n",
        "        out = model(word_ix)\n",
        "        # print('for loss func, out shape:', out.shape, 'y shape:', y.shape)\n",
        "        loss = loss_func(out, y)\n",
        "        if reg_option == 'L1':\n",
        "            l1_lambda = 0.001\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "            loss = loss + l1_lambda * l1_norm\n",
        "        elif reg_option == 'L2':\n",
        "            l2_lambda = 0.001\n",
        "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
        "            loss = loss + l2_lambda * l2_norm\n",
        "\n",
        "        # backpropogation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # accuracy\n",
        "        _, pred_idx = torch.max(out, 1)\n",
        "        # print('pred_idx shape:', pred_idx.shape)\n",
        "        pred = np.array([])\n",
        "        for idx in pred_idx:\n",
        "            pred = np.append(pred, lookup_char[int(idx)])\n",
        "        correct += sum(pred == y_label)\n",
        "        # print record every 100 letters\n",
        "        if batch % 1000 == 0 and batch != 0:\n",
        "        # if batch:\n",
        "            loss, current = loss.item()/batch_size, batch\n",
        "            iters = 1000\n",
        "            then = datetime.datetime.now()\n",
        "            iters /= (then - now).total_seconds()\n",
        "            print(f\"loss: {loss:>6f} [{current:>5d}/{n_batches}] ({iters:.1f} batch/sec)\")\n",
        "            train_loss.append(loss)\n",
        "\n",
        "            acc = float(correct) / ((batch+1)*batch_size) *100\n",
        "            print('train accuracy: %.2f%%' % acc)\n",
        "            # print('out shape:', out.shape)\n",
        "            # print('pred:', pred)\n",
        "            # print('predicted label:', pred, '; true label:', train_data[batch+window])\n",
        "            train_acc.append(acc)\n",
        "            now = then\n",
        "    return train_loss, train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ebTmtz5P_Lng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8f42fbee-82d1-4b87-963d-d11bce6e6d55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef make_pred(out, true_embedding):\\n    min_cos = float('inf')\\n    pred = ''\\n    for i in ascii_ls:\\n        cos = torch.nn.CosineSimilarity(out[i], true_embedding)\\n        if cos < min_cos:\\n            pred = chr(i)\\n            min_cos = cos\\n    return pred\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\"\"\"\n",
        "def make_pred(out, true_embedding):\n",
        "    min_cos = float('inf')\n",
        "    pred = ''\n",
        "    for i in ascii_ls:\n",
        "        cos = torch.nn.CosineSimilarity(out[i], true_embedding)\n",
        "        if cos < min_cos:\n",
        "            pred = chr(i)\n",
        "            min_cos = cos\n",
        "    return pred\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L_VraWnlSJGH"
      },
      "outputs": [],
      "source": [
        "def test(test_data, test_label, batch_size, window, model, loss_func):\n",
        "    model.eval()\n",
        "    n_batches = int(len(test_data) / batch_size)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    num_examples = 0\n",
        "    actual = []\n",
        "    predicted = []\n",
        "    with torch.no_grad():\n",
        "        for batch in range(n_batches):\n",
        "            # Initialize\n",
        "            word_ix = np.empty([0, window])\n",
        "            y_label = np.array([])\n",
        "            y = torch.zeros([0, len(char_ls)], dtype=torch.float32)\n",
        "            # word_ix includes a n_batches of text window; if not in ascii list, replace with random\n",
        "            for sample in range(batch_size):\n",
        "                word_ix_sample = []\n",
        "                for x in test_data[batch+sample]:\n",
        "                    if x in lookup_embed.keys():\n",
        "                        word_ix_sample.append(lookup_embed[x])\n",
        "                    else:\n",
        "                        word_ix_sample.append(np.random.randint(0,len(char_ls)-1))\n",
        "                word_ix = np.vstack((word_ix, word_ix_sample))\n",
        "                y_label = np.append(y_label, test_label[batch+sample])\n",
        "                word_iy_sample = lookup_embed[y_label[-1]] if y_label[-1] in lookup_embed.keys() else np.random.randint(0,len(char_ls)-1)\n",
        "                y_sample = torch.zeros([1, len(char_ls)], dtype=torch.float32)\n",
        "                y_sample[0, word_iy_sample] = 1\n",
        "                y = torch.vstack((y, y_sample))\n",
        " \n",
        "            word_ix, y = torch.LongTensor(word_ix).to(device), y.to(device)\n",
        "            \n",
        "            # make some predictions and get the error\n",
        "            out = model(word_ix)\n",
        "            test_loss += loss_func(out, y).item()\n",
        "            _, pred_idx = torch.max(out, 1)\n",
        "            pred = np.array([])\n",
        "            for idx in pred_idx:\n",
        "                pred = np.append(pred, lookup_char[int(idx)])\n",
        "            correct += sum(pred == y_label)\n",
        " \n",
        "            actual.extend(y_label)\n",
        "            predicted.extend(pred)\n",
        "            # num_examples += batch_size\n",
        "    num_examples = n_batches*batch_size\n",
        "    test_loss /= num_examples\n",
        "    print('# of correct predictions:', correct)\n",
        "    # print('# of samples:', num_examples)\n",
        "    test_acc = float(correct) / num_examples * 100\n",
        "    print(f\"Avg Loss: {test_loss:>8f}\")\n",
        "    print('Avg Validation Accuracy: %.2f%%\\n' % test_acc)\n",
        "    return test_loss, test_acc, actual, predicted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSob7t7-x79l",
        "outputId": "4c05688b-aa07-40a3-cc0a-878688d89ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (embedding): Embedding(36, 10)\n",
            "  (hidden): ModuleList(\n",
            "    (0): Linear(in_features=40, out_features=10, bias=True)\n",
            "    (1): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (2): Linear(in_features=5, out_features=15, bias=True)\n",
            "    (3): Linear(in_features=15, out_features=10, bias=True)\n",
            "  )\n",
            "  (bnorm): ModuleList(\n",
            "    (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (ReLU): ReLU()\n",
            "  (out): Linear(in_features=10, out_features=10, bias=True)\n",
            "  (cos): CosineSimilarity()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Epoch 1\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013747 [ 1000/4146] (31.6 batch/sec)\n",
            "train accuracy: 35.39%\n",
            "loss: 0.013037 [ 2000/4146] (32.2 batch/sec)\n",
            "train accuracy: 39.43%\n",
            "loss: 0.013062 [ 3000/4146] (30.9 batch/sec)\n",
            "train accuracy: 41.78%\n",
            "loss: 0.012934 [ 4000/4146] (30.8 batch/sec)\n",
            "train accuracy: 41.55%\n",
            "# of correct predictions: 50\n",
            "Avg Loss: 0.013966\n",
            "Avg Validation Accuracy: 4.88%\n",
            "\n",
            "Epoch 2\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013087 [ 1000/4146] (31.1 batch/sec)\n",
            "train accuracy: 41.39%\n",
            "loss: 0.013016 [ 2000/4146] (31.6 batch/sec)\n",
            "train accuracy: 41.51%\n",
            "loss: 0.013046 [ 3000/4146] (30.8 batch/sec)\n",
            "train accuracy: 41.74%\n",
            "loss: 0.013034 [ 4000/4146] (31.4 batch/sec)\n",
            "train accuracy: 41.48%\n",
            "# of correct predictions: 100\n",
            "Avg Loss: 0.013816\n",
            "Avg Validation Accuracy: 9.77%\n",
            "\n",
            "Epoch 3\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012981 [ 1000/4146] (31.0 batch/sec)\n",
            "train accuracy: 40.15%\n",
            "loss: 0.012856 [ 2000/4146] (32.1 batch/sec)\n",
            "train accuracy: 41.23%\n",
            "loss: 0.013209 [ 3000/4146] (31.7 batch/sec)\n",
            "train accuracy: 40.74%\n",
            "loss: 0.012971 [ 4000/4146] (31.3 batch/sec)\n",
            "train accuracy: 39.84%\n",
            "# of correct predictions: 68\n",
            "Avg Loss: 0.013906\n",
            "Avg Validation Accuracy: 6.64%\n",
            "\n",
            "Epoch 4\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012959 [ 1000/4146] (31.2 batch/sec)\n",
            "train accuracy: 36.21%\n",
            "loss: 0.012919 [ 2000/4146] (32.5 batch/sec)\n",
            "train accuracy: 37.54%\n",
            "loss: 0.013097 [ 3000/4146] (31.5 batch/sec)\n",
            "train accuracy: 38.52%\n",
            "loss: 0.013083 [ 4000/4146] (31.2 batch/sec)\n",
            "train accuracy: 38.45%\n",
            "# of correct predictions: 70\n",
            "Avg Loss: 0.013917\n",
            "Avg Validation Accuracy: 6.84%\n",
            "\n",
            "Epoch 5\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013029 [ 1000/4146] (31.1 batch/sec)\n",
            "train accuracy: 38.50%\n",
            "loss: 0.013123 [ 2000/4146] (32.0 batch/sec)\n",
            "train accuracy: 38.30%\n",
            "loss: 0.012983 [ 3000/4146] (32.0 batch/sec)\n",
            "train accuracy: 39.15%\n",
            "loss: 0.013267 [ 4000/4146] (31.9 batch/sec)\n",
            "train accuracy: 38.61%\n",
            "# of correct predictions: 52\n",
            "Avg Loss: 0.013989\n",
            "Avg Validation Accuracy: 5.08%\n",
            "\n",
            "Epoch 6\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012810 [ 1000/4146] (31.3 batch/sec)\n",
            "train accuracy: 37.99%\n",
            "loss: 0.012874 [ 2000/4146] (31.6 batch/sec)\n",
            "train accuracy: 39.67%\n",
            "loss: 0.012842 [ 3000/4146] (30.8 batch/sec)\n",
            "train accuracy: 40.07%\n",
            "loss: 0.013147 [ 4000/4146] (30.9 batch/sec)\n",
            "train accuracy: 39.62%\n",
            "# of correct predictions: 70\n",
            "Avg Loss: 0.013946\n",
            "Avg Validation Accuracy: 6.84%\n",
            "\n",
            "Epoch 7\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013078 [ 1000/4146] (30.6 batch/sec)\n",
            "train accuracy: 36.33%\n",
            "loss: 0.012945 [ 2000/4146] (30.9 batch/sec)\n",
            "train accuracy: 38.22%\n",
            "loss: 0.012875 [ 3000/4146] (31.4 batch/sec)\n",
            "train accuracy: 39.27%\n",
            "loss: 0.012997 [ 4000/4146] (31.6 batch/sec)\n",
            "train accuracy: 39.14%\n",
            "# of correct predictions: 59\n",
            "Avg Loss: 0.013937\n",
            "Avg Validation Accuracy: 5.76%\n",
            "\n",
            "Epoch 8\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013028 [ 1000/4146] (31.3 batch/sec)\n",
            "train accuracy: 39.20%\n",
            "loss: 0.012922 [ 2000/4146] (31.8 batch/sec)\n",
            "train accuracy: 38.70%\n",
            "loss: 0.012866 [ 3000/4146] (31.9 batch/sec)\n",
            "train accuracy: 39.43%\n",
            "loss: 0.013022 [ 4000/4146] (32.0 batch/sec)\n",
            "train accuracy: 39.24%\n",
            "# of correct predictions: 89\n",
            "Avg Loss: 0.013828\n",
            "Avg Validation Accuracy: 8.69%\n",
            "\n",
            "Epoch 9\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012948 [ 1000/4146] (30.6 batch/sec)\n",
            "train accuracy: 37.19%\n",
            "loss: 0.012880 [ 2000/4146] (31.5 batch/sec)\n",
            "train accuracy: 38.77%\n",
            "loss: 0.012853 [ 3000/4146] (31.6 batch/sec)\n",
            "train accuracy: 38.81%\n",
            "loss: 0.013064 [ 4000/4146] (30.8 batch/sec)\n",
            "train accuracy: 38.89%\n",
            "# of correct predictions: 88\n",
            "Avg Loss: 0.013882\n",
            "Avg Validation Accuracy: 8.59%\n",
            "\n",
            "Epoch 10\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013078 [ 1000/4146] (30.2 batch/sec)\n",
            "train accuracy: 36.14%\n",
            "loss: 0.012970 [ 2000/4146] (31.3 batch/sec)\n",
            "train accuracy: 37.54%\n",
            "loss: 0.013019 [ 3000/4146] (30.7 batch/sec)\n",
            "train accuracy: 38.46%\n",
            "loss: 0.013099 [ 4000/4146] (30.7 batch/sec)\n",
            "train accuracy: 37.75%\n",
            "# of correct predictions: 76\n",
            "Avg Loss: 0.013899\n",
            "Avg Validation Accuracy: 7.42%\n",
            "\n",
            "Epoch 11\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012945 [ 1000/4146] (31.1 batch/sec)\n",
            "train accuracy: 35.54%\n",
            "loss: 0.012988 [ 2000/4146] (31.4 batch/sec)\n",
            "train accuracy: 35.26%\n",
            "loss: 0.013024 [ 3000/4146] (31.3 batch/sec)\n",
            "train accuracy: 35.81%\n",
            "loss: 0.013263 [ 4000/4146] (31.3 batch/sec)\n",
            "train accuracy: 35.63%\n",
            "# of correct predictions: 61\n",
            "Avg Loss: 0.013931\n",
            "Avg Validation Accuracy: 5.96%\n",
            "\n",
            "Epoch 12\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012968 [ 1000/4146] (30.7 batch/sec)\n",
            "train accuracy: 36.00%\n",
            "loss: 0.012839 [ 2000/4146] (31.6 batch/sec)\n",
            "train accuracy: 36.99%\n",
            "loss: 0.013004 [ 3000/4146] (30.8 batch/sec)\n",
            "train accuracy: 37.33%\n",
            "loss: 0.013324 [ 4000/4146] (31.5 batch/sec)\n",
            "train accuracy: 36.30%\n",
            "# of correct predictions: 61\n",
            "Avg Loss: 0.013922\n",
            "Avg Validation Accuracy: 5.96%\n",
            "\n",
            "Epoch 13\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013113 [ 1000/4146] (31.3 batch/sec)\n",
            "train accuracy: 33.23%\n",
            "loss: 0.013062 [ 2000/4146] (31.8 batch/sec)\n",
            "train accuracy: 33.76%\n",
            "loss: 0.012946 [ 3000/4146] (31.8 batch/sec)\n",
            "train accuracy: 34.08%\n",
            "loss: 0.013111 [ 4000/4146] (31.1 batch/sec)\n",
            "train accuracy: 34.45%\n",
            "# of correct predictions: 56\n",
            "Avg Loss: 0.013983\n",
            "Avg Validation Accuracy: 5.47%\n",
            "\n",
            "Epoch 14\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013071 [ 1000/4146] (30.9 batch/sec)\n",
            "train accuracy: 32.91%\n",
            "loss: 0.013139 [ 2000/4146] (31.3 batch/sec)\n",
            "train accuracy: 33.05%\n",
            "loss: 0.012953 [ 3000/4146] (31.0 batch/sec)\n",
            "train accuracy: 33.35%\n",
            "loss: 0.013354 [ 4000/4146] (31.3 batch/sec)\n",
            "train accuracy: 33.33%\n",
            "# of correct predictions: 63\n",
            "Avg Loss: 0.013946\n",
            "Avg Validation Accuracy: 6.15%\n",
            "\n",
            "Epoch 15\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013051 [ 1000/4146] (30.1 batch/sec)\n",
            "train accuracy: 33.16%\n",
            "loss: 0.013138 [ 2000/4146] (30.4 batch/sec)\n",
            "train accuracy: 33.40%\n",
            "loss: 0.012841 [ 3000/4146] (30.3 batch/sec)\n",
            "train accuracy: 34.47%\n",
            "loss: 0.013173 [ 4000/4146] (31.6 batch/sec)\n",
            "train accuracy: 34.77%\n",
            "# of correct predictions: 48\n",
            "Avg Loss: 0.013986\n",
            "Avg Validation Accuracy: 4.69%\n",
            "\n",
            "Epoch 16\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013117 [ 1000/4146] (30.6 batch/sec)\n",
            "train accuracy: 32.54%\n",
            "loss: 0.013047 [ 2000/4146] (31.6 batch/sec)\n",
            "train accuracy: 33.21%\n",
            "loss: 0.012862 [ 3000/4146] (31.7 batch/sec)\n",
            "train accuracy: 34.89%\n",
            "loss: 0.013074 [ 4000/4146] (31.3 batch/sec)\n",
            "train accuracy: 35.42%\n",
            "# of correct predictions: 59\n",
            "Avg Loss: 0.013922\n",
            "Avg Validation Accuracy: 5.76%\n",
            "\n",
            "Epoch 17\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.012996 [ 1000/4146] (31.2 batch/sec)\n",
            "train accuracy: 35.22%\n",
            "loss: 0.012963 [ 2000/4146] (31.9 batch/sec)\n",
            "train accuracy: 36.53%\n",
            "loss: 0.012879 [ 3000/4146] (31.9 batch/sec)\n",
            "train accuracy: 36.58%\n",
            "loss: 0.013070 [ 4000/4146] (31.7 batch/sec)\n",
            "train accuracy: 36.51%\n",
            "# of correct predictions: 135\n",
            "Avg Loss: 0.013699\n",
            "Avg Validation Accuracy: 13.18%\n",
            "\n",
            "Epoch 18\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013077 [ 1000/4146] (31.5 batch/sec)\n",
            "train accuracy: 34.25%\n",
            "loss: 0.013124 [ 2000/4146] (30.7 batch/sec)\n",
            "train accuracy: 34.85%\n",
            "loss: 0.012980 [ 3000/4146] (31.6 batch/sec)\n",
            "train accuracy: 35.74%\n",
            "loss: 0.013122 [ 4000/4146] (31.6 batch/sec)\n",
            "train accuracy: 35.35%\n",
            "# of correct predictions: 82\n",
            "Avg Loss: 0.013826\n",
            "Avg Validation Accuracy: 8.01%\n",
            "\n",
            "Epoch 19\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013233 [ 1000/4146] (31.1 batch/sec)\n",
            "train accuracy: 31.26%\n",
            "loss: 0.013208 [ 2000/4146] (30.8 batch/sec)\n",
            "train accuracy: 31.25%\n",
            "loss: 0.012925 [ 3000/4146] (30.9 batch/sec)\n",
            "train accuracy: 32.77%\n",
            "loss: 0.013140 [ 4000/4146] (30.6 batch/sec)\n",
            "train accuracy: 33.16%\n",
            "# of correct predictions: 68\n",
            "Avg Loss: 0.013910\n",
            "Avg Validation Accuracy: 6.64%\n",
            "\n",
            "Epoch 20\n",
            "------------------------------- \n",
            "\n",
            "loss: 0.013146 [ 1000/4146] (30.0 batch/sec)\n",
            "train accuracy: 31.75%\n",
            "loss: 0.012969 [ 2000/4146] (30.9 batch/sec)\n",
            "train accuracy: 33.30%\n",
            "loss: 0.013071 [ 3000/4146] (30.2 batch/sec)\n",
            "train accuracy: 33.43%\n",
            "loss: 0.013142 [ 4000/4146] (30.6 batch/sec)\n",
            "train accuracy: 33.38%\n",
            "# of correct predictions: 77\n",
            "Avg Loss: 0.013884\n",
            "Avg Validation Accuracy: 7.52%\n",
            "\n",
            "Test accuracy: 7.52%\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "NUM_TARGETS = len(char_ls)\n",
        "EMBED_DIM = 10\n",
        "WINDOW = 4\n",
        "h_sizes = [10, 5, 15, 10]\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 20\n",
        "\n",
        "net = Net(h_sizes=h_sizes, n_features=WINDOW, num_words=NUM_TARGETS, embed_dim=EMBED_DIM, out_size=EMBED_DIM,dropout=None)     # define the network\n",
        "print(net)  # net architecture\n",
        "net = net.float().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_func = torch.nn.CrossEntropyLoss()  # this is for regression mean squared loss\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "pred = []\n",
        "actual = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t + 1}\\n------------------------------- \\n\")\n",
        "    losses, acces = train(texts_valid_txt, batch_size, WINDOW, net, loss_func, optimizer, reg_option='L1')\n",
        "    valid_losses, valid_acces ,predicteds, actuals = test(window_test, label_test, batch_size, WINDOW, net, loss_func)\n",
        "    train_loss.append(losses)\n",
        "    train_acc.append(acces)\n",
        "    valid_loss.append(valid_losses)\n",
        "    valid_acc.append(valid_acces)\n",
        "    pred.append(predicteds)\n",
        "    actual.append(actuals)\n",
        "# test_loss, test_acc, predicted, actual = test(test_loader, model, loss_func)\n",
        "\n",
        "# Could add a condition that interrupts training when the loss doesn't change much\n",
        "print('Test accuracy: %.2f%%' % valid_acc[-1])\n",
        "print('Done!')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9MCkWXVdcuU",
        "outputId": "17ee2b4c-7532-479b-c798-0fdd38d778f0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.013799377949908376,\n",
              " 0.013859351864084601,\n",
              " 0.014039351372048259,\n",
              " 0.013986459700390697,\n",
              " 0.01394128892570734]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EkRi5EJwvcl_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as skl\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def confusion(actual, predicted):\n",
        "    cf_matrix = confusion_matrix(actual, predicted)\n",
        "    return sns.heatmap(cf_matrix, annot=True, cmap=\"Blues\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YxJNveKu_0G1"
      },
      "outputs": [],
      "source": [
        "# confusion_matix=confusion(actual, pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Plot\n",
        "loss1, = plt.plot([i for i in range(len(train_loss))], torch.tensor(train_loss).mean(axis=1),\n",
        "                    label='train loss')\n",
        "loss2, = plt.plot([i for i in range(len(valid_loss))], valid_loss, color='orange',\n",
        "                    label='valid loss')\n",
        "plt.legend([loss1, loss2], ['train', 'valid'])\n",
        "plt.xlabel('# of epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "IjvxXbsKimDc",
        "outputId": "4c1ecda6-4434-47fa-f099-63d11b8baec5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accurary Plot\n",
        "loss1, = plt.plot([i for i in range(len(train_acc))], torch.tensor(train_acc).mean(axis=1),\n",
        "                    label='train acc')\n",
        "loss2, = plt.plot([i for i in range(len(valid_acc))], valid_acc, color='orange',\n",
        "                    label='valid acc')\n",
        "plt.legend([loss1, loss2], ['train', 'valid'])\n",
        "plt.xlabel('# of epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n",
        "plt.savefig('256_lr0.005_L1_noDrop.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "sG-ZZx2NoFGf",
        "outputId": "24b3cb2f-0dd3-4474-b596-e681b2107e6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S70jUzkNe9BN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML 349 - Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}